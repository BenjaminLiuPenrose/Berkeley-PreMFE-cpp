{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from numpy import dot, matmul\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.regression.linear_model import OLS\n",
    "from statsmodels.tsa.tsatools import lagmat\n",
    "from statsmodels.stats.diagnostic import het_arch, het_white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Data_PG_UN.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>PG</th>\n",
       "      <th>UN</th>\n",
       "      <th>HH</th>\n",
       "      <th>MKT</th>\n",
       "      <th>RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1994-01-31</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.004329</td>\n",
       "      <td>0.0247</td>\n",
       "      <td>0.0312</td>\n",
       "      <td>0.0025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1994-02-28</td>\n",
       "      <td>0.016397</td>\n",
       "      <td>0.020473</td>\n",
       "      <td>-0.0121</td>\n",
       "      <td>-0.0235</td>\n",
       "      <td>0.0021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1994-03-31</td>\n",
       "      <td>-0.019355</td>\n",
       "      <td>-0.061245</td>\n",
       "      <td>-0.0504</td>\n",
       "      <td>-0.0451</td>\n",
       "      <td>0.0027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1994-04-30</td>\n",
       "      <td>-0.078947</td>\n",
       "      <td>-0.087739</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1994-05-31</td>\n",
       "      <td>0.082419</td>\n",
       "      <td>0.092478</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date        PG        UN      HH     MKT      RF\n",
       "0  1994-01-31  0.008772  0.004329  0.0247  0.0312  0.0025\n",
       "1  1994-02-28  0.016397  0.020473 -0.0121 -0.0235  0.0021\n",
       "2  1994-03-31 -0.019355 -0.061245 -0.0504 -0.0451  0.0027\n",
       "3  1994-04-30 -0.078947 -0.087739  0.0164  0.0095  0.0027\n",
       "4  1994-05-31  0.082419  0.092478  0.0092  0.0089  0.0031"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capm(y, x, rf):\n",
    "    # ols reg\n",
    "    n = y.shape[0]\n",
    "    k = x.shape[1]\n",
    "    ols_y = y - rf\n",
    "    ols_x = np.concatenate((np.ones((n, 1)), x - matmul(rf, np.ones((1, k)) ) ), axis = 1).reshape(n, k+1)\n",
    "#     print(ols_x.shape, matmul(rf, np.ones((1, k))).shape, x.shape )\n",
    "    \n",
    "    aux = inv( \n",
    "        dot(ols_x.T, ols_x)\n",
    "    ) \n",
    "    ols_coeff = dot(\n",
    "        dot(aux, ols_x.T),\n",
    "        ols_y\n",
    "    )\n",
    "    ols_y_hat = dot(\n",
    "        ols_x,\n",
    "        ols_coeff\n",
    "    )\n",
    "#     print(dot(aux, ols_x.T).shape, ols_y.shape)\n",
    "#     print(aux.shape, ols_coeff.shape, ols_y_hat.shape)\n",
    "    alpha = ols_coeff[0]\n",
    "    beta = ols_coeff[1:]\n",
    "#     print(alpha, beta)\n",
    "    \n",
    "    # r2\n",
    "    y_mean = np.mean(ols_y)\n",
    "    tot = np.sum( (ols_y - y_mean) ** 2 )\n",
    "    reg = np.sum( (ols_y - ols_y_hat) ** 2 )\n",
    "    res = np.sum( (ols_y_hat - y_mean) ** 2 )\n",
    "    r_squared = 1 - res / tot\n",
    "    r_squared_adjusted = 1 - res * (n - 1) / (tot * (n - k - 1)) \n",
    "#     print(r_squared, r_squared_adjusted)\n",
    "    \n",
    "    # variance-covariance matrix, under homoskedastic\n",
    "    expected_res_squared = np.mean( (ols_y_hat - ols_y) ** 2 )\n",
    "    matrix_var_cov = aux * expected_res_squared\n",
    "    \n",
    "    # Wald test\n",
    "    coeff_var = np.diag(matrix_var_cov)\n",
    "    coeff_std = np.sqrt(coeff_var) \n",
    "    alpha_std = coeff_std[0]\n",
    "    beta_std = coeff_std[1:]\n",
    "    t_value = (beta * 1.0 - .0) / beta_std \n",
    "    \n",
    "    ### Heterskedastic\n",
    "    # access whether there is signifiant evidence for heterskedastic\n",
    "#     print((ols_y_hat - ols_y).shape)\n",
    "    White_stat = het_white(ols_y_hat - ols_y, ols_x)\n",
    "    ARCH_stat = het_arch((ols_y_hat - ols_y).reshape(-1))\n",
    "    \n",
    "    # confidence interval\n",
    "    confidence_interval = {\n",
    "        \"90_percent\": (beta - 1.645 * beta_std, beta + 1.645 * beta_std),\n",
    "        \"95_percent\": (beta - 1.960 * beta_std, beta + 1.960 * beta_std),\n",
    "        \"99_percent\": (beta - 2.576 * beta_std, beta + 2.576 * beta_std)\n",
    "    }\n",
    "    \n",
    "    # variance-covariance matrix under heterskedastic\n",
    "    matrix_D = np.diag( ((ols_y_hat - ols_y) ** 2).reshape(-1) )\n",
    "    matrix_var_cov_heter = dot(\n",
    "        dot(\n",
    "            aux,\n",
    "            dot(\n",
    "                dot(ols_x.T, matrix_D),\n",
    "                ols_x\n",
    "            )\n",
    "        ),\n",
    "        aux\n",
    "    )\n",
    "    \n",
    "    # gls reg\n",
    "    gls_aux = inv( \n",
    "        dot(\n",
    "            dot(\n",
    "                ols_x.T,\n",
    "                matrix_D\n",
    "            ),\n",
    "            ols_x\n",
    "        )\n",
    "    ) \n",
    "    gls_coeff = dot(\n",
    "        dot(\n",
    "            dot(gls_aux, ols_x.T), \n",
    "            matrix_D\n",
    "        ),\n",
    "        ols_y\n",
    "    )\n",
    "    gls_alpha = gls_coeff[0]\n",
    "    gls_beta = gls_coeff[1:]\n",
    "    \n",
    "    # confidence interval under heterskedastic\n",
    "    coeff_var_heter = np.diag(matrix_var_cov_heter)\n",
    "    coeff_std_heter = np.sqrt(coeff_var_heter)\n",
    "    alpha_std_heter = coeff_std_heter[0]\n",
    "    beta_std_heter = coeff_std_heter[1:]\n",
    "#     print(beta_std_heter, alpha_std_heter)\n",
    "    \n",
    "    confidence_interval_heter = {\n",
    "        \"90_percent\": (beta - 1.645 * beta_std_heter, beta + 1.645 * beta_std_heter),\n",
    "        \"95_percent\": (beta - 1.960 * beta_std_heter, beta + 1.960 * beta_std_heter),\n",
    "        \"99_percent\": (beta - 2.576 * beta_std_heter, beta + 2.576 * beta_std_heter)\n",
    "    }\n",
    "    \n",
    "    # Wald test\n",
    "    t_value_heter = (beta * 1.0 - .0) / beta_std_heter\n",
    "    \n",
    "    ### Others\n",
    "    # AIC, BIC and HQIC\n",
    "    logLikelihood =  -0.5 * n * (np.log(2 * np.pi) + np.log(np.sum(beta_std ** 2)) + 1)\n",
    "    AIC = k * 2.0 / n - 2 * logLikelihood / n  \n",
    "    BIC = k * np.log(n) * 2.0 / n - 2 * logLikelihood / n\n",
    "    HQIC = k * np.log(np.log(n)) * 2.0 / n - 2 * logLikelihood / n\n",
    "    \n",
    "    # DW stat, BG stat\n",
    "    DW_stat = durbin_watson(ols_y_hat - ols_y)\n",
    "    BG_stat = breusch_godfrey(ols_y_hat - ols_y, ols_x)\n",
    "    \n",
    "    # JB stat\n",
    "    JB_stat = jarque_bera(ols_y_hat - ols_y)\n",
    "    \n",
    "    ### Muticolinearity\n",
    "    # cond number\n",
    "    condition_number = np.linalg.cond(dot(ols_x.T, ols_x))\n",
    "    \n",
    "    # Ramsey's RESET test\n",
    "    Ramsey_RESET = reset_ramsey(ols_y_hat - ols_y, ols_x, ols_y, ols_y_hat)\n",
    "    \n",
    "    # scatter plot \n",
    "    rtn = {\n",
    "        \"sample_size\": n,\n",
    "        \"regressors\": k,\n",
    "        \"alpha\": alpha,\n",
    "        \"beta\": beta,\n",
    "        \"coeff\": ols_coeff,\n",
    "        \"gls_alpha\": gls_alpha,\n",
    "        \"gls_beta\": gls_beta,\n",
    "        \"gls_coeff\": gls_coeff,\n",
    "        \n",
    "        \"r_squared\": r_squared,\n",
    "        \"r_squared_adjusted\": r_squared_adjusted,\n",
    "        \n",
    "        \"matrix_var_cov\": matrix_var_cov,\n",
    "        \n",
    "        \"t_value\": t_value,\n",
    "        \n",
    "        \"White_stat\": White_stat,\n",
    "        \"ARCH_stat\": ARCH_stat,\n",
    "        \n",
    "        \"confidence_interval\": confidence_interval,\n",
    "        \n",
    "        \"matrix_var_cov_heter\": matrix_var_cov_heter,\n",
    "        \n",
    "        \"confidence_interval_heter\": confidence_interval_heter,\n",
    "        \n",
    "        \"t_value_heter\": t_value_heter,\n",
    "        \n",
    "        \"AIC\": AIC,\n",
    "        \"BIC\": BIC,\n",
    "        \"HQIC\": HQIC,\n",
    "        \n",
    "        \"DW_stat\": DW_stat,\n",
    "        \"BG_stat\": BG_stat,\n",
    "        \n",
    "        \"JB_stat\": JB_stat,\n",
    "        \n",
    "        \"condition_number\": condition_number,\n",
    "        \n",
    "        \"Ramset_RESET\": Ramsey_RESET\n",
    "    }\n",
    "    return rtn\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def durbin_watson(resids, axis=0):\n",
    "    \"\"\"\n",
    "    return DW_stat\n",
    "    \"\"\"\n",
    "    resids = np.asarray(resids)\n",
    "    diff_resids = np.diff(resids, 1, axis=axis)\n",
    "    dw = np.sum(diff_resids**2, axis=axis) / np.sum(resids**2, axis=axis)\n",
    "    return dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jarque_bera(resids, axis=0):\n",
    "    \"\"\"\n",
    "    return:\n",
    "    jb_test, jb_pv, skew, kurtosis\n",
    "    \"\"\"\n",
    "    resids = np.asarray(resids)\n",
    "    # Calculate residual skewness and kurtosis\n",
    "    skew = stats.skew(resids, axis=axis)\n",
    "    kurtosis = 3 + stats.kurtosis(resids, axis=axis)\n",
    "\n",
    "    # Calculate the Jarque-Bera test for normality\n",
    "    n = resids.shape[axis]\n",
    "    jb = (n / 6.) * (skew ** 2 + (1 / 4.) * (kurtosis - 3) ** 2)\n",
    "    jb_pv = stats.chi2.sf(jb, 2)\n",
    "\n",
    "    return jb, jb_pv, skew, kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breusch_godfrey(resids, exog, nlags=None):\n",
    "    '''\n",
    "    return\n",
    "    BG stats\n",
    "    '''\n",
    "    x = np.asarray(resids).reshape(-1)\n",
    "    exog_old = exog\n",
    "    nobs = x.shape[0]\n",
    "    if nlags is None:\n",
    "        nlags = np.trunc(12. * np.power(nobs/100., 1/4.))#nobs//4  #TODO: check default, or do AIC/BIC\n",
    "        nlags = int(nlags)\n",
    "\n",
    "    x = np.concatenate((np.zeros(nlags), x))\n",
    "\n",
    "\n",
    "    xdall = lagmat(x[:,None], nlags, trim='both')\n",
    "    nobs = xdall.shape[0]\n",
    "    xdall = np.c_[np.ones((nobs,1)), xdall]\n",
    "    xshort = x[-nobs:]\n",
    "    exog = np.column_stack((exog_old, xdall))\n",
    "    k_vars = exog.shape[1]\n",
    "\n",
    "    resols = OLS(xshort, exog).fit()\n",
    "    ft = resols.f_test(np.eye(nlags, k_vars, k_vars - nlags))\n",
    "    fval = ft.fvalue\n",
    "    fpval = ft.pvalue\n",
    "    fval = np.squeeze(fval)[()]   #TODO: fix this in ContrastResults\n",
    "    fpval = np.squeeze(fpval)[()]\n",
    "    lm = nobs * resols.rsquared\n",
    "    lmpval = stats.chi2.sf(lm, nlags)\n",
    "\n",
    "    return lm, lmpval, fval, fpval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_ramsey(res, exog, ols_y, ols_y_hat, degree=5):\n",
    "    '''\n",
    "    RESET Ramsey stats\n",
    "    '''\n",
    "    order = degree + 1\n",
    "    k_vars = exog.shape[1]\n",
    "\n",
    "    y_fitted_vander = np.vander(ols_y_hat.reshape(-1), order)[:, :-2] #drop constant\n",
    "    exog = np.column_stack((exog, y_fitted_vander))\n",
    "    res_aux = OLS(ols_y, exog).fit()\n",
    "    #r_matrix = np.eye(degree, exog.shape[1], k_vars)\n",
    "    r_matrix = np.eye(degree-1, exog.shape[1], k_vars)\n",
    "\n",
    "    return res_aux.f_test(r_matrix) #, r_matrix, res_aux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AIC': -1.8839579062540148,\n",
      " 'ARCH_stat': (19.60818832755058,\n",
      "               0.2383882398775724,\n",
      "               1.2395068671945766,\n",
      "               0.23899189833901005),\n",
      " 'BG_stat': (23.12959631091408,\n",
      "             0.08142679372129774,\n",
      "             1.5812127465772183,\n",
      "             0.0792652454067308),\n",
      " 'BIC': -1.849291625169573,\n",
      " 'DW_stat': array([2.31394602]),\n",
      " 'HQIC': -1.8785150081814894,\n",
      " 'JB_stat': (array([29.59168708]),\n",
      "             array([3.75186148e-07]),\n",
      "             array([-0.17047603]),\n",
      "             array([4.60433945])),\n",
      " 'Ramset_RESET': <class 'statsmodels.stats.contrast.ContrastResults'>\n",
      "<F test: F=array([[1.6189636]]), p=0.16986196930817227, df_denom=258, df_num=4>,\n",
      " 'White_stat': (6.198067177610722,\n",
      "                0.04509275949070361,\n",
      "                3.1374775116036404,\n",
      "                0.045033179154105346),\n",
      " 'alpha': array([0.00804347]),\n",
      " 'beta': array([[0.0524295]]),\n",
      " 'coeff': array([[0.00804347],\n",
      "       [0.0524295 ]]),\n",
      " 'condition_number': 514.8175504461651,\n",
      " 'confidence_interval': {'90_percent': (array([[-0.10216264]]),\n",
      "                                        array([[0.20702164]])),\n",
      "                         '95_percent': (array([[-0.13176539]]),\n",
      "                                        array([[0.23662439]])),\n",
      "                         '99_percent': (array([[-0.18965521]]),\n",
      "                                        array([[0.29451422]]))},\n",
      " 'confidence_interval_heter': {'90_percent': (array([[-0.13174684]]),\n",
      "                                              array([[0.23660585]])),\n",
      "                               '95_percent': (array([[-0.16701465]]),\n",
      "                                              array([[0.27187366]])),\n",
      "                               '99_percent': (array([[-0.23598282]]),\n",
      "                                              array([[0.34084182]]))},\n",
      " 'gls_alpha': array([0.01709798]),\n",
      " 'gls_beta': array([[0.3296083]]),\n",
      " 'gls_coeff': array([[0.01709798],\n",
      "       [0.3296083 ]]),\n",
      " 'matrix_var_cov': array([[ 1.74836363e-05, -5.37728499e-05],\n",
      "       [-5.37728499e-05,  8.83167374e-03]]),\n",
      " 'matrix_var_cov_heter': array([[ 1.73373722e-05, -5.30367346e-05],\n",
      "       [-5.30367346e-05,  1.25353337e-02]]),\n",
      " 'r_squared': 0.9988224135096664,\n",
      " 'r_squared_adjusted': 0.9988179189047415,\n",
      " 'regressors': 1,\n",
      " 'sample_size': 264,\n",
      " 't_value': array([[0.55789726]]),\n",
      " 't_value_heter': array([[0.46828235]])}\n"
     ]
    }
   ],
   "source": [
    "y = np.array(data[[\"UN\"]])\n",
    "x = np.array(data[[\"MKT\"]])\n",
    "rf = np.array(data[[\"RF\"]])\n",
    "rtn = capm(y, x, rf)\n",
    "pprint.pprint(rtn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AIC': -0.6476473406639189,\n",
      " 'ARCH_stat': (21.06123882371936,\n",
      "               0.17616860892935352,\n",
      "               1.3398840900574611,\n",
      "               0.1741835404834825),\n",
      " 'BG_stat': (21.52682217040645,\n",
      "             0.12082465246320606,\n",
      "             1.4559956146686803,\n",
      "             0.12246909030461185),\n",
      " 'BIC': -0.5783147784950353,\n",
      " 'DW_stat': array([2.2815962]),\n",
      " 'HQIC': -0.6367615445188679,\n",
      " 'JB_stat': (array([29.2676887]),\n",
      "             array([4.41166117e-07]),\n",
      "             array([-0.15356408]),\n",
      "             array([4.60198978])),\n",
      " 'Ramset_RESET': <class 'statsmodels.stats.contrast.ContrastResults'>\n",
      "<F test: F=array([[2.67729464]]), p=0.03234991695953332, df_denom=257, df_num=4>,\n",
      " 'White_stat': (10.413815731591601,\n",
      "                0.064323941206679,\n",
      "                2.119014856035554,\n",
      "                0.06360504458525529),\n",
      " 'alpha': array([0.00824356]),\n",
      " 'beta': array([[ 0.09675669],\n",
      "       [-0.07486515]]),\n",
      " 'coeff': array([[ 0.00824356],\n",
      "       [ 0.09675669],\n",
      "       [-0.07486515]]),\n",
      " 'condition_number': 1428.8835087243895,\n",
      " 'confidence_interval': {'90_percent': (array([[-0.1003937 , -0.11010408],\n",
      "       [-0.27201555, -0.28172593]]),\n",
      "                                        array([[0.29390709, 0.30361747],\n",
      "       [0.12228524, 0.13199563]])),\n",
      "                         '95_percent': (array([[-0.1381459 , -0.14971572],\n",
      "       [-0.30976775, -0.32133757]]),\n",
      "                                        array([[0.33165929, 0.34322911],\n",
      "       [0.16003745, 0.17160726]])),\n",
      "                         '99_percent': (array([[-0.21197244, -0.22717848],\n",
      "       [-0.38359428, -0.39880033]]),\n",
      "                                        array([[0.40548582, 0.42069187],\n",
      "       [0.23386398, 0.24907002]]))},\n",
      " 'confidence_interval_heter': {'90_percent': (array([[-0.15224467, -0.16372562],\n",
      "       [-0.32386651, -0.33534746]]),\n",
      "                                              array([[0.34575805, 0.35723901],\n",
      "       [0.17413621, 0.18561716]])),\n",
      "                               '95_percent': (array([[-0.19992578, -0.21360521],\n",
      "       [-0.37154762, -0.38522705]]),\n",
      "                                              array([[0.39343917, 0.4071186 ],\n",
      "       [0.22181732, 0.23549675]])),\n",
      "                               '99_percent': (array([[-0.29316884, -0.31114752],\n",
      "       [-0.46479069, -0.48276937]]),\n",
      "                                              array([[0.48668223, 0.50466091],\n",
      "       [0.31506038, 0.33303906]]))},\n",
      " 'gls_alpha': array([0.01635375]),\n",
      " 'gls_beta': array([[ 0.34139899],\n",
      "       [-0.03495224]]),\n",
      " 'gls_coeff': array([[ 0.01635375],\n",
      "       [ 0.34139899],\n",
      "       [-0.03495224]]),\n",
      " 'matrix_var_cov': array([[ 1.75731474e-05, -2.86771282e-05, -4.22629427e-05],\n",
      "       [-2.86771282e-05,  1.43636066e-02, -9.36299966e-03],\n",
      "       [-4.22629427e-05, -9.36299966e-03,  1.58133727e-02]]),\n",
      " 'matrix_var_cov_heter': array([[ 1.79191665e-05,  3.63092230e-05, -1.45685176e-04],\n",
      "       [ 3.63092230e-05,  2.29124555e-02, -1.61751205e-02],\n",
      "       [-1.45685176e-04, -1.61751205e-02,  2.50740604e-02]]),\n",
      " 'r_squared': 0.9974832407664558,\n",
      " 'r_squared_adjusted': 0.9974639552550876,\n",
      " 'regressors': 2,\n",
      " 'sample_size': 264,\n",
      " 't_value': array([[ 0.80732662,  0.76942939],\n",
      "       [-0.62466614, -0.59534329]]),\n",
      " 't_value_heter': array([[ 0.63921242,  0.61103866],\n",
      "       [-0.49458837, -0.47278902]])}\n"
     ]
    }
   ],
   "source": [
    "y = np.array(data[[\"UN\"]])\n",
    "x = np.array(data[[\"MKT\", \"HH\"]])\n",
    "rf = np.array(data[[\"RF\"]])\n",
    "rtn = capm(y, x, rf)\n",
    "pprint.pprint(rtn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I prefer first model since its conditional number is smaller and adjusted r_squared is higher, which means the estimators are good and the dependent variables can explain the independent variables well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The current market beta for UL, under the CAPM, is is beta estimate of first model 0.0524"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
